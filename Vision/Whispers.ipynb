{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "750ee351",
   "metadata": {},
   "source": [
    "## Whispers\n",
    "https://rsokl.github.io/CogWeb/Video/Whispers.html#Whispers-Algorithm\n",
    "\n",
    "Install: \n",
    "`conda install -c conda-forge networkx`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c77753",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " Provides tools for performing and analyzing the whispers label-propagation algorithm to\n",
    " determine how many unique individuals are represented amongst a collection of pictures.\n",
    "\n",
    " See VisualProject/face_rec/Whispers_Tutorial for a walk through of the tooling.\n",
    "\"\"\"\n",
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from typing import Callable, Dict, List, Optional, Sequence, Tuple, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from facenet_models import FacenetModel\n",
    "from facenet_pytorch.models.utils.detect_face import crop_resize\n",
    "from skimage import io\n",
    "\n",
    "__all__ = [\n",
    "    \"labeled_pics_to_descriptors\",\n",
    "    \"create_adjacency_matrix\",\n",
    "    \"plot_adjacency_distr\",\n",
    "    \"create_graph\",\n",
    "    \"run_propagation\",\n",
    "    \"plot_graph\",\n",
    "]\n",
    "\n",
    "\n",
    "def labeled_pics_to_descriptors(\n",
    "    data_dir: Union[str, Path], accept_prob: float = 0.95\n",
    ") -> Tuple[np.ndarray, Tuple[str, ...], np.ndarray]:\n",
    "    \"\"\"Given labeled directories of pictures individual people, returns the face-descriptors and\n",
    "    the corresponding names.\n",
    "\n",
    "    This function warns when more or less than one face is detected in a picture.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_dir : str\n",
    "        Directory containing named-directories of pictures of individuals.\n",
    "\n",
    "        For example\n",
    "\n",
    "        data_dir/\n",
    "           - Ryan/\n",
    "              - jpgs of Ryan\n",
    "           - John/\n",
    "              - jpgs of John\n",
    "            ...\n",
    "\n",
    "    accept_prob : float\n",
    "        The minimum face-detection probability/confidence that is required to accept\n",
    "        a detection.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[numpy.ndarray, Tuple[str, ...], numpy-ndarray]\n",
    "        NxD array of N face-descriptors, a length-N list of the names corresponding\n",
    "        to the descriptors, and an Nx160x160x3 array of cropped and resized faces.\n",
    "    \"\"\"\n",
    "\n",
    "    model = FacenetModel()\n",
    "\n",
    "    data_dir = Path(data_dir)\n",
    "    names = sorted(i.split(os.sep)[-1] for i in glob(str(data_dir / \"*\")))\n",
    "    pics = [\n",
    "        (name, pic)\n",
    "        for name in names\n",
    "        for pic in glob(str(data_dir / name / \"*\"))\n",
    "        if pic.split(\".\")[-1].lower() in {\"jpg\", \"png\", \"jpeg\"}\n",
    "    ]\n",
    "\n",
    "    joint = []\n",
    "    used_names = []\n",
    "    faces = []\n",
    "    for name, pic in pics:\n",
    "        img = io.imread(pic)\n",
    "        boxes, probs, _ = model.detect(img)\n",
    "\n",
    "        # each picture should contain one face\n",
    "        if (np.array(probs) > accept_prob).sum() != 1:\n",
    "            print(\n",
    "                f\"Warning: {name} contains a picture with {(np.array(probs) > accept_prob).sum()} faces:\\n\\t{pic}\"\n",
    "            )\n",
    "            continue\n",
    "        for box, prob in zip(boxes, probs):\n",
    "            if prob < accept_prob:\n",
    "                continue\n",
    "            cropped_face = np.array(\n",
    "                [crop_resize(img, [int(max(0, coord)) for coord in box], 160)]\n",
    "            )\n",
    "            joint += [\n",
    "                d\n",
    "                for n, d in enumerate(model.compute_descriptors(img, boxes))\n",
    "                if probs[n] > accept_prob\n",
    "            ]\n",
    "            used_names.append(name)\n",
    "            faces.append(cropped_face)\n",
    "\n",
    "    return np.vstack(joint), tuple(used_names), np.vstack(faces)\n",
    "\n",
    "\n",
    "def create_adjacency_matrix(\n",
    "    descriptors: np.ndarray,\n",
    "    cutoff: Optional[float] = None,\n",
    "    weighting_func: Callable[[np.ndarray], np.ndarray] = None,\n",
    "):\n",
    "    \"\"\"Produce an adjacency matrix of cosine distances between descriptor\n",
    "    vectors. A cutoff value can be provided such that distances exceeding\n",
    "    the cutoff are set to 0. A weighting function can be supplied to perform\n",
    "    a mapping on all non-zero weights.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    descriptors : numpy.ndarray, shape=(N, D)\n",
    "        Face-descriptor vectors for N faces.\n",
    "\n",
    "    cutoff : Optional[float]\n",
    "        The cutoff above which all distances are set to 0.\n",
    "\n",
    "    weighting_func : Callable[[numpy.ndarray], numpy.ndarray]\n",
    "        The mapping applied to all non-zero entries in the adjacency matrix.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray, shape=(N, N)\n",
    "        The adjacency matrix. The indexing corresponds to the order of the descriptors.\n",
    "    \"\"\"\n",
    "\n",
    "    descriptors = descriptors / np.linalg.norm(descriptors, axis=1, keepdims=True)\n",
    "    similarity = descriptors @ descriptors.T\n",
    "    out = 1 - similarity\n",
    "    np.fill_diagonal(out, 0.0)\n",
    "\n",
    "    # set dists above cutoff to 0\n",
    "    if cutoff is not None:\n",
    "        keep = np.logical_and(0 < out, out <= cutoff)\n",
    "        thresh = np.where(keep)\n",
    "        out[~keep] = 0.0\n",
    "    else:\n",
    "        thresh = np.ones(out.shape, dtype=bool)\n",
    "\n",
    "    # map non-zero dists to weight values\n",
    "    if weighting_func is not None:\n",
    "        out[thresh] = weighting_func(out[thresh])\n",
    "    return out\n",
    "\n",
    "\n",
    "def plot_adjacency_distr(descriptors: np.ndarray) -> Tuple[plt.Figure, plt.Axes]:\n",
    "    \"\"\"Plot a histogram of the adjacency matrix of cosine distances between descriptors.\n",
    "\n",
    "    Only the upper-triangle of the matrix is binned - no double counting or trivial 0s.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    descriptors : numpy.ndarray, shape=(N, D)\n",
    "        Face-descriptors for N faces\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[matplotlib.fig.Fig, matplotlib.axis.Axes]\n",
    "        The figure and axes of the histogram plot.\n",
    "    \"\"\"\n",
    "\n",
    "    adj = create_adjacency_matrix(descriptors)\n",
    "    p = np.triu(adj)\n",
    "    p = p[p > 1e-6]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.hist(p, bins=100, label=\"All People\")\n",
    "    ax.set_title(\"Distribution of face-descriptor cosine distances\")\n",
    "    ax.set_xlabel(\"Descriptor distance\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "class Node:\n",
    "    \"\"\" Describes a node in a graph, and the edges connected\n",
    "        to that node.\n",
    "        \n",
    "        This class definition differs somewhat from the one here: \n",
    "        https://rsokl.github.io/CogWeb/Video/Whispers.html#Useful-Code\n",
    "        \"\"\"\n",
    "    \n",
    "    def __init__(self, init_class, id_, neighbors_, truth_=None):\n",
    "    \n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        id : int\n",
    "            A unique identifier for this node. Should be a\n",
    "            value in [0, N-1], if there are N nodes in total.\n",
    "\n",
    "        neighbors : Sequence[int]\n",
    "            The node-IDs of the neighbors of this node.\n",
    "\n",
    "        descriptor : numpy.ndarray\n",
    "            The shape-(512,) descriptor vector for the face that this node corresponds to.\n",
    "\n",
    "        truth : Optional[str]\n",
    "            If you have truth data, for checking your clustering algorithm,\n",
    "            you can include the label to check your clusters at the end.\n",
    "            If this node corresponds to a picture of Ryan, this truth\n",
    "            value can just be \"Ryan\"    \"\"\"\n",
    "\n",
    "        self.id = id_    # a unique identified for this node - this should never change\n",
    "\n",
    "        self.label = init_class\n",
    "\n",
    "        # (n1_ID, n2_ID, ...)\n",
    "        # The IDs of this nodes neighbors. Empty if no neighbors\n",
    "        self.neighbors = tuple(neighbors_)\n",
    "\n",
    "        self.truth = truth_\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "def create_graph(adj: np.ndarray, truth: Optional[Sequence[str]]) -> Tuple[Node, ...]:\n",
    "    \"\"\"Create a graph from the NxN adjacency matrix. See 'Notes' for information.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    adj : np.ndarray, shape=(N, N)\n",
    "        The adjacency matrix for which to construct a graph, where N is the number of nodes.\n",
    "\n",
    "    truth : Optional[Sequential[str]]\n",
    "        The true labels corresponding to each instance.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[Node, ...]\n",
    "        See Notes\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The graph is simply a tuple of N node-instances, ordered according to the adjacency matrix.\n",
    "\n",
    "    Each node has the attributes:\n",
    "        - id : int\n",
    "            A unique identifier - corresponds to its index in the graph and its index in the\n",
    "            adjacency matrix.\n",
    "\n",
    "        - label : int\n",
    "            The integer-ID that labels the cluster the node belongs to. Initialized to a\n",
    "            random integer in [0, N)\n",
    "\n",
    "        - neighbors : Tuple[integer]\n",
    "            The IDs for the neighbors of the node.\n",
    "\n",
    "        - truth : Union[None, Tuple[str]]\n",
    "            The name of the person that the node corresponds to. If `None`,\n",
    "            no truth values are recorded.\n",
    "    \"\"\"\n",
    "\n",
    "    neighbors = defaultdict(list)\n",
    "    for node, neighbor in zip(*np.where(adj > 0)):\n",
    "        neighbors[node].append(neighbor)\n",
    "\n",
    "    # nodes with no neighbors need an empty neighbors list\n",
    "    no_neighbors = np.where(adj.sum(axis=1) == 0.0)[0]\n",
    "    for node in no_neighbors:\n",
    "        neighbors[node] = []\n",
    "\n",
    "    if truth is None:\n",
    "        truth = [None for i in range(adj.shape[0])]\n",
    "    labels = list(range(adj.shape[0]))\n",
    "    random.shuffle(labels)\n",
    "    return tuple(\n",
    "        Node(labels[n], n, neighbors[n], truth[n]) for n in range(adj.shape[0])\n",
    "    )\n",
    "\n",
    "\n",
    "def _compute_pairwise_metrics(graph: Tuple[Node, ...]) -> Tuple[float, float]:\n",
    "    \"\"\"Compute the pair-precision and pair-recall accuracies for a graph.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    graph : Tuple[Node, ...]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[float, float]\n",
    "        Precision and recall accuracies, respectively.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    precision = (same_truth & same_class) / [(same_truth & same_class) + (diff_truth & same_class)]\n",
    "\n",
    "      - High precision: clustered conservatively\n",
    "\n",
    "      - Low precision: aggressive clustering\n",
    "\n",
    "    recall = (same_truth & same_class) / [(same_truth & same_class) + (same_truth & diff_class)]\n",
    "\n",
    "      - High recall: inclusive clusters\n",
    "\n",
    "      - Low recall: dispersive clusters\n",
    "    \"\"\"\n",
    "    from collections import defaultdict\n",
    "    from itertools import combinations\n",
    "\n",
    "    categories = defaultdict(int)\n",
    "    for n1, n2 in combinations(graph, 2):\n",
    "        t = \"truth\" if n1.truth == n2.truth else \"~truth\"\n",
    "        l = \"label\" if n1.label == n2.label else \"~label\"\n",
    "        categories[f\"{t},{l}\"] += 1\n",
    "\n",
    "    pair_prec = categories[\"truth,label\"] / (\n",
    "        categories[\"truth,label\"] + categories[\"truth,~label\"]\n",
    "    )\n",
    "    pair_recall = categories[\"truth,label\"] / (\n",
    "        categories[\"truth,label\"] + categories[\"~truth,label\"]\n",
    "    )\n",
    "    return pair_prec, pair_recall\n",
    "\n",
    "\n",
    "def run_propagation(\n",
    "    graph: Tuple[Node, ...],\n",
    "    weights: Optional[np.ndarray],\n",
    "    num_it: int,\n",
    "    stat_rate: Optional[int],\n",
    ") -> Tuple[Tuple[Node, ...], Dict[str, List[float]]]:\n",
    "    \"\"\"Randomly choose a node and update its label, repeating for\n",
    "    the specified number of iteration. Update the node's label\n",
    "    to agree with the most popular labels amongst its neighbors.\n",
    "\n",
    "    If weights are supplied, then each neighbor's contribution\n",
    "    is weighted. The label with the highest accumulated weight\n",
    "    is adopted.\n",
    "\n",
    "    The number of unique labels, pairwise precision-accuracy, and\n",
    "    pairwise recall-accuracy are recorded during the run.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    graph : Tuple[Node, ... ]\n",
    "        The graph of N nodes to propagate labels through.\n",
    "\n",
    "    weights : Union[None, numpy.ndarray]\n",
    "        `None` or an NxN adjacency matrix of weights to be used for label propagation.\n",
    "\n",
    "    num_it : int\n",
    "        The number of iterations for which to perform the propagation.\n",
    "\n",
    "    stat_rate : Union[None, int]\n",
    "        The frequency with which stats will be recorded. If `None`, no stats are recorded.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[Tuple[Node, ...], Dict[str, List[float]]]\n",
    "        The graph post-propagation, and the recorded stats.\n",
    "\n",
    "        The stat-dictionary's keys are 'num_labels', 'precision', and 'recall'.\n",
    "    \"\"\"\n",
    "\n",
    "    import random\n",
    "    from collections import Counter, defaultdict\n",
    "    from itertools import groupby, takewhile\n",
    "\n",
    "    def first(x):\n",
    "        return x[0]\n",
    "\n",
    "    def _propagate_label(node, graph, weights):\n",
    "        \"\"\" Returns most-whispered label.\"\"\"\n",
    "        if weights is not None:\n",
    "            # accumulate total weights for each label; label with max weight is propagated to node\n",
    "            cls_wght = zip(\n",
    "                (graph[i].label for i in node.neighbors),\n",
    "                weights[node.id, node.neighbors],\n",
    "            )\n",
    "            cls_wght = sorted(\n",
    "                cls_wght, key=first\n",
    "            )  # [(label, weight), ...] in sorted by label\n",
    "            most_common = (\n",
    "                (k, sum(amt for _, amt in v)) for k, v in groupby(cls_wght, key=first)\n",
    "            )\n",
    "\n",
    "            # [(label, total_weight), ...] sorted by descending weight\n",
    "            most_common = sorted(most_common, key=lambda x: x[1], reverse=True)\n",
    "        else:\n",
    "            # most common label is propagated to node\n",
    "            most_common = Counter(graph[i].label for i in node.neighbors).most_common()\n",
    "        _max = most_common[0][1]\n",
    "        # if tie, randomly choose from tied labels\n",
    "        return random.choice(\n",
    "            [lbl for lbl, cnt in takewhile(lambda x: x[1] == _max, most_common)]\n",
    "        )\n",
    "\n",
    "    stats = defaultdict(list)\n",
    "    for it in range(num_it):\n",
    "        node = graph[random.randint(0, len(graph) - 1)]\n",
    "        if node.neighbors:\n",
    "            node.label = _propagate_label(node, graph, weights)\n",
    "\n",
    "        # record pairwise stats and number of distinct labels\n",
    "        if stat_rate is not None and it % stat_rate == 0:\n",
    "            stats[\"num_labels\"].append(len(set(n.label for n in graph)))\n",
    "            prec, recall = _compute_pairwise_metrics(graph)\n",
    "            stats[\"precision\"].append(prec)\n",
    "            stats[\"recall\"].append(recall)\n",
    "    return graph, stats\n",
    "\n",
    "\n",
    "def plot_graph(graph, adj):\n",
    "    \"\"\"Use the package networkx to produce a diagrammatic plot of the graph, with\n",
    "    the nodes in the graph colored according to their current labels.\n",
    "\n",
    "    Note that only 20 unique colors are available for the current color map,\n",
    "    so common colors across nodes may be coincidental.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    graph : Tuple[Node, ...]\n",
    "        The graph to plot\n",
    "    adj : numpy.ndarray, shape=(N, N)\n",
    "        The adjacency-matrix for the graph. Nonzero entries indicate\n",
    "        the presence of edges.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[matplotlib.fig.Fig, matplotlib.axis.Axes]\n",
    "        The figure and axes for the plot.\n",
    "    \"\"\"\n",
    "    import matplotlib.cm as cm\n",
    "    import matplotlib.pyplot as plt\n",
    "    import networkx as nx\n",
    "    import numpy as np\n",
    "\n",
    "    g = nx.Graph()\n",
    "    for n, node in enumerate(graph):\n",
    "        g.add_node(n)\n",
    "\n",
    "    g.add_edges_from(zip(*np.where(np.triu(adj) > 0)))\n",
    "    pos = nx.spring_layout(g)\n",
    "\n",
    "    color = list(iter(cm.tab20b(np.linspace(0, 1, len(set(i.label for i in graph))))))\n",
    "    color_map = dict(zip(sorted(set(i.label for i in graph)), color))\n",
    "    colors = [color_map[i.label] for i in graph]\n",
    "    fig, ax = plt.subplots()\n",
    "    nx.draw_networkx_nodes(\n",
    "        g, pos=pos, ax=ax, nodelist=range(len(graph)), node_color=colors\n",
    "    )\n",
    "    nx.draw_networkx_edges(g, pos, ax=ax, edgelist=g.edges())\n",
    "    return fig, ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7cdf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b24d981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35bfbe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
